# 1장 - 사용자 수에 따른 규모 확장성

- 수백만 사용자를 지원하는 시스템을 설계하는 것은 도전적인 과제

## 단일 서버

- 웹 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행
- 사용자 요청 처리 흐름
  - 사용자는 도메인 이름으로 웹 사이트에 접속 (DNS에 질의 후 IP 주소로 변환, DNS는 제 3사업자가 제공)
  - DNS 조회 후 IP 주소가 반환
  - 해당 IP 주소로 HTTP 요청 전달
  - 요청받은 웹 서버는 HTML or JSON 형태의 응답 반환
- 실제 요청이 오는 곳
  - 웹 애플리케이션 (서버 구현용 언어, 클라이언트 구현용 언어)
  - 모바일 앱 (모바일 앱과 웹 서버 간 통신을 위해서는 HTTP 프로토콜을 이용, JSON을 포맷으로 사용)

## 데이터베이스

- 사용자가 많으면 데이터 베이스용 서버를 둠
  - 웹/모바일 트래픽 처리 서버와 데이터베이스 서버를 분리해 각각을 독립적으로 확장

### 어떤 데이터베이스를 사용할 것인가?

- 관계형 데이터베이스
  - RDBMS라고도 부름
  - MySQL, 오라클 데이터베이스, PostgreSQL 등
  - 자료를 테이블과 열, 칼럼으로 표현
  - 여러 테이블에 있는 데이터를 관계에 따라 조인하여 합칠 수 있음
- 비 관계형 데이터 베이스
  - NoSQL이라고도 부름
  - CouchDB, Neo4j, Cassandra, HBase, Amazon DynamoDB 등
  - 키-값 저장소, 그래프 저장소, 칼럼 저장소, 문서 저장소 등으로도 분류
  - 일반적으로 조인 연산 지원 X
  - 아주 낮은 응답 지연시간 요구, 다루는 데이터가 비정형 일 때, 데이트의 직렬화 역직렬화만 가능하면 되는 상황, 아주 많은 양의 데이터를 저장할 필요가 있을 때 선택

## 수직적 규모 확장 vs 수평적 규모 확장

- 수직적 규모 확장
  - 스케일 업
  - 서버에 고사양 자원을 추가하는 행위
  - 서버로 유입되는 트래픽 양이 적을 때는 좋음
  - 단순함이 큰 장점
  - 규모 확장의 한계, 자동복구 방안이나 다중화 방안을 제시할 수 없는 한계
- 수평적 규모 확장
  - 스케일 아웃
  - 더 많은 서버를 추가하여 성능을 개선

### 로드밸런서

- 부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할
- 로드밸런서 동작 과정
  - 사용자는 로드밸런서의 공개 IP 주소로 접속
  - 웹 서버는 클라이언트의 접속을 직접 처리 X
  - 서버 간 통신(로드밸런서와 웹 서버)에는 사설 IP 주소(같은 네트워크에 속한 서버 사이의 통신에만 쓰임)가 이용
- 부하 분산 집합에 웹 서버를 추가함으로써 장애 자동복구와 웹 계층의 가용성 향상
  - 서버 1 다운 시 모든 트래픽은 서버 2로 전송
  - 모든 서버로 트래픽을 감당할 수 없을 시 웹 서버 계층에 더 많은 서버 추가

### 데이터베이스 다중화

- 서버 사이에 주(master)-부(slave) 관계를 설정하고 데이터 원분은 주 서버에, 사본은 부 서버에 저장하는 방식
  - 쓰기 연산은 마스터에서만 지원 (insert, delete, update 등)
  - 부 데이터베이스는 주 데이터베이스로부터 사본을 전달받고 읽기 연산만을 지원
  - 읽기 연산의 질의가 병렬로 처리될 수 있으므로 성능이 좋아짐
  - 여러 장소에 다중화 시킴으로써 안정성, 가용성 향상
- 데이터베이스 서버 가운데 하나가 다운된다면?
  - 부 서버가 한 대뿐 일 때 다운될 시 새로운 부 서버가 장애를 대체하기 전까지 주 데이터베이스로 읽기 연산 전달
  - 부 서버가 여러 개일 시 읽기 연산은 나머지 부 데이터베이스 서버들로 분산
  - 주 데이터베이스 서버가 다운 시 부 데이터베이스 서버가 새로운 주 서버가 됨 (다중 마스터, 원형 다중화 등의 방식 존재)

### 로드밸런서와 데이터베이스 다중화를 고려한 설계안

- 사용자는 DNS로부터 로드밸런서의 공개 IP 주소 받은 후 접속
- HTTP 요청은 분산된 서버 중 하나로 전달
- 웹 서버는 사용자의 데이터를 부 데이터베이스 서버에서 읽음
- 변경 연산은 주 데이터베이스로 전달 (데이터 추가, 삭제, 갱신 연산 등)

## 캐시

- 값비싼 연산 결과나 자주 참조되는 데이터를 메모리 안에 둔 뒤 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소
  - 데이터베이스를 얼마나 자주 호출되냐에 좌우되는 애플리케이션의 성능을 향상시켜줌

### 캐시 계층

- 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠름
- 성능 개선, 데이터베이스의 부하 감소, 캐시 계층의 규모를 독립적으로 확장하는 것이 가능
- 주도형 캐시 전략
  - 캐시에 응답이 저장되어 있으면 반환, 없는 경우엔 데이터베이스 질의를 통해 찾은 뒤 캐시에 저장 후 반환
- 캐시 서버들이 일반적으로 널리 쓰이는 프로그래밍 언어로 API를 제공

### 캐시 사용 시 유의할 점

- 캐시는 어떤 상황에 바람직한지?
  - 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어날 때
- 어떤 데이터를 캐시에 두어야 하는지?
  - 비휘발성 메모리에 데이터를 두므로 영속적인 데이터는 X
- 캐시에 보관된 데이터는 어떻게 만료?
  - 정책을 마련해 둘 것
  - 만료 기한은 너무 짧거나 너무 길지 않게
- 일관성은 어떻게 유지?
  - 일관성 : 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부
  - 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되어야 함
  - 여러 지역에 걸쳐 시스템을 확장해 나가는 경우 캐시와 저장소 사이의 일관성을 유지하는 것은 어려운 문제가 됨
- 장애에는 어떻게 대처?
  - 캐시 서버를 한 대만 두는 경우 해당 서버는 `단일 장애 지점(Single Point of Failure, SPOF)`이 되어버릴 수 있음
  - SPOF : 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우
  - SPOF를 피하기 위해서 여러 지역에 걸쳐 캐시 서버를 분산해야 함
- 캐시 메모리는 얼마나 크게?
  - 너무 작으면 데이터가 너무 자주 캐시에서 밀려나버림 (eviction)
  - 캐시 메모리를 과할당하여 데이터가 갑자기 늘어났을 때 생길 문제도 방지
- 데이터 방출 정책은?
  - 데이터 방출 정책 : 캐시가 꽉 차버렸을 때 기존 데이터를 내보내는 정책
  - LRU : 마지막으로 사용된 시점이 가장 오래된 데이터를 내보냄
  - LFU : 사용된 빈도가 가장 낮은 데이터를 내보내는 정책
  - FIFO : 가장 먼저 캐시에 들어온 데이터를 가장 먼저 내보내는 정책

## 콘텐츠 전송 네트워크(CDN)

- CDN
  - 정적 콘텐츠를 전송하는 데 쓰이는 지리적으로 분산된 서버의 네트워크
  - 이미지, 비디오, CSS, JavaScript 파일 등을 캐시 가능
- 동적 콘텐츠 캐싱
  - 상대적으로 새로운 개념
  - 요청 경로, 질의 문자열, 쿠키, 요청 헤더 등의 정보에 기반하여 HTML 페이지를 캐싱하는 것
- 사용자가 웹 사이트 방문 시 그 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달
- CDN과 사용자가 멀 수록 웹사이트는 천천히 로드
- CDN 동작 과정
  - 사용자가 이미지 URL을 통해 접근, URL의 도메인은 CDN 사업자가 제공
  - CDN 서버의 캐시에 해당 이미지가 없는 경우 서버는 원본 서버에 요청하여 파일을 가져옴 (웹 서버 or 아마존 S3와 같은 온라인)
  - 원본 서버가 파일을 CDN 서버에 반환, 응답 HTTP에는 TTL(Time-To-Live) 값 포함(파일이 얼마나 오래 캐시 될 수 있는지)
  - CDN 서버는 파일을 캐시하고 사용자에게 반환, TTL에 명시된 시간까지 캐시
  - 다른 사용자가 이미지 요청 시 만료되지 않은 이미지는 캐시를 통해 처리

### CDN 사용 시 고려해야 할 사항

- 비용
  - CDN은 보통 제 3 사업자에 의해 운영
  - CDN으로 들어가고 나가는 데이터 전송 양에 따라 요금을 내야 함
  - 자주 사용되지 않는 콘텐츠는 CDN에서 뺄 것
- 적절한 만료 시한 설정
  - 너무 길지도, 짧지도 않게 정해야 함
- CDN 장애에 대한 대처 방안
  - CDN 자체가 죽었을 경우를 고려
  - CDN이 응답하지 않을 시 해당 상황 감지 후 원본 서버로부터 콘텐츠를 가져오는 등의 구성 필요
- 콘텐츠 무효화 방법
  - 만료되지 않은 콘텐츠라 하더라도 CDN에서 제거할 수 있는 방법
  - CDN 서비스 사업자가 제공하는 API를 이용
  - 콘텐츠의 다른 버전을 서비스하도록 오브젝트 버저닝 이용

## 무상태(stateless) 웹 계층

- 웹 계층을 수평적으로 확장하기 위해서는 상태 정보를 웹 계층에서 제거해야 함
  - 상태 정보를 관계형 데이터베이스나 NoSQL 같은 지속성 저장소에 보관하고 필요할 때 가져오도록 함 -> 무상태 웹 계층

### 상태 정보 의존적인 아키텍처

- 상태 정보를 보관하는 서버는 클라이언트 정보를 유지하여 요청들 사이에 공유
- 문제
  - 같은 클라이언트의 요청은 항상 같은 서버로 전송되어야 함
  - 같은 서버로 고정하기 위해선 로드밸런서가 고정 세션 기능을 제공
  - 고정 세션은 로드밸런서에 부담을 주고 뒷단에 서버 추가와 제거를 까다롭게 함

### 무상태 아키택처

- 사용자로부터의 HTTP 요청은 어떤 웹 서버로도 전달 가능
- 상태 정보가 필요할 경우 공유 저장소(관계형 DB, NoSQL, Memcached/Redis 등등 ...)로부터 데이터를 가져옴
  - 상태 정보는 웹 서버로부터 물리적으로 분리
- 단순하고, 안정적이며 규모 확장이 쉬운 구조

## 데이터 센터

- 지리적 라우팅 (geoDNS-routing or geo-routing)
  - 장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내되는 절차
  - 사용자의 위치에 따라 도메인 이름을 어떤 IP 주소로 변환할지 정할 수 있도록 해주는 DNS 서비스
- 데이터 센터 중 하나에 심각한 장애가 발생하면 모든 트래픽은 장애가 없는 데이터 센터로 전송
- 다중 데이터 센터 아키택처를 만들기 위해 해결해야 할 것
  - 트래픽 우회 (올바른 데이터 센터로 트래픽을 보내야 함)
  - 데이터 동기화 (여러 데이터 센터에 걸쳐 다중화 하는 것)
  - 테스트와 배포 (여러 위치에서 테스트해야 하고 배포 도구도 중요)

## 메시지 큐

- 시스템의 규모 확장을 위해 컴포넌트를 분리하여 독립적으로 확장될 수 있도록 할 때 사용
- 메시지의 무손실(소비자가 꺼낼 때까지)을 보장하고 비동기 통신을 지원하는 컴포넌트
- 메시지의 버퍼 역할을 하며 비동기적으로 전송
- 기본 아키텍처
  - 생산자가 메시지를 만들어 메시지 큐에 발행
  - 큐에는 소비자 혹은 구독자와 연결돼있고 메시지를 받아 그에 맞는 동작 수행
- 서비스 또는 서버 간 결합이 느슨해짐
  - 규모 확장 가능
  - 소비자는 생산자 서비스가 가용한 상태가 아니더라도 메시지 수신 가능
- 사용 예 : 사진 보정 애플리케이션과 같은 오래 걸릴 수 있는 프로세스

## 로그, 메트릭 그리고 자동화

- 웹 사이트 규모가 커지면 필수적으로 투자해야 하는 것들
- 로그
  - 에러 로그를 모니터링하는 것은 중요 (오류와 문제들을 보다 쉽게 찾아줌)
  - 서버 단위로 모니터링도 가능
  - 로그를 단일 서비스로 모아주는 도구를 활용하여 더 편리하게 검색 및 조회 가능
- 메트릭
  - 사업 현황에 관한 유용한 정보를 얻거나 시스템의 현상태 손쉽게 파악
  - 호스트 단위 메트릭(CPU, 메모리, 디스크 I/O), 종합 메트릭(DB 성능, 캐시 성능), 핵심 비즈니스 메트릭 등이 유용
- 자동화
  - 크고 복잡해진 시스템의 생산성을 높이기 위해 사용
  - 지속적 통합, 빌드, 테스트, 배포 등의 절차를 자동화 가능

### 메시지 큐, 로그, 메트릭, 자동화 등을 반영하여 수정한 설계안

- 메시지 큐는 각 컴포넌트가 느슨히 결합될 수 있도록 하고 결함에 대한 내성을 높임
- 로그, 모니터링, 메트릭, 자동화 등을 지원하기 위한 장치를 추가

## 데이터베이스의 규모 확장

- 수직적 확장
  - 스케일 업이라고 부름
  - 기존 서버에 더 많거나 고성능의 자원(CPU, RAM, 디스크 등)을 증설하는 방법
  - 서버 하드웨어는 한계가 있으므로 CPU나 RAM을 무한 증설할 수 없는 한계
  - SPOF로 인한 위험성
  - 고비용
- 수평적 확장
  - 샤딩이라고도 부름
  - 더 많은 서버를 추가함으로써 성능을 향상시킬 수 있도록 함
  - 샤딩은 대규모 데이터베이스를 샤드라고 부르는 작은 단위로 분할하는 기술
  - 모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복 X
  - 샤딩 키(파티션 키)를 어떻게 정하느냐가 샤딩 전략을 구현할 때 고려해야 할 가장 중요한 것
- 샤딩을 도입하면 풀어야 할 문제들
  - 데이터의 재 샤딩 : 데이터가 너무 많아져서 지금 샤드로 감당 X 일 때, 샤드 간 데이터 분포가 균등하지 못할 때(샤드 소진), 안정 해시 기법을 활용
  - 유명인사 문제(핫스팟 키 문제) : 특정 샤드에 질의가 집중되어 서버에 과부하, 유명인사 각각에 샤드 하나씩 할당하거나 더 잘개 쪼갬
  - 조인과 비정규화 : 많은 샤드로 쪼개질 시 여러 샤드에 걸친 데이터를 조인하기가 힘듦, 데이터를 비정규화하여 하나의 테이블에서 질의가 수행될 수 있도록 하는 방법이 있음

## 백만 사용자, 그리고 그 이상

- 시스템의 규모를 확장하는 것은 지속적이고 반복적(iterative)인 과정
  - 새로운 전략을 도입하고 지속적으로 시스템을 가다듬어야 함
- 이번 장에서 살펴보았던 기법들
  - 웹 계층은 무상태 계층으로
  - 모든 계층에 다중화 도입
  - 가능한 한 많은 데이터를 캐시 할 것
  - 여러 데이터 센터를 지원할 것
  - 정적 콘텐츠는 CDN을 통해 서비스할 것
  - 데이터 계층은 샤딩을 통해 그 규모를 확장할 것
  - 각 계층은 독립적 서비스로 분할할 것
  - 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것
